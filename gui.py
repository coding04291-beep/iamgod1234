import streamlit as st
import requests
import re
import pandas as pd
import time
from urllib.parse import unquote
import io

# --- ë¸”ë¡œê·¸ ìˆ˜ì§‘ í•¨ìˆ˜ ---
def get_blog_posts(blog_id):
    posts = []
    page = 1
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}

    progress_bar = st.progress(0)
    status_text = st.empty()

    while page <= 20:  # ìµœëŒ€ 20íŽ˜ì´ì§€ê¹Œì§€ ìˆ˜ì§‘
        status_text.text(f"í˜„ìž¬ {page}íŽ˜ì´ì§€ ìˆ˜ì§‘ ì¤‘...")
        url = f"https://blog.naver.com/PostTitleListAsync.naver?blogId={blog_id}&viewdate=&currentPage={page}"
        
        try:
            response = requests.get(url, headers=headers)
            text = response.text
            
            titles = re.findall(r'"titleText":"([^"]+)"', text)
            dates = re.findall(r'"addDate":"([^"]+)"', text)
            log_nos = re.findall(r'"logNo":"([^"]+)"', text)
            
            if not titles: break
                
            for i in range(len(titles)):
                posts.append({
                    'ì œëª©': unquote(titles[i]).replace('\n', ' ').strip(),
                    'ë‚ ì§œ': dates[i] if i < len(dates) else '',
                    'ë§í¬': f"https://blog.naver.com/{blog_id}/{log_nos[i]}" if i < len(log_nos) else ''
                })
            
            page += 1
            progress_bar.progress(page / 20)
            time.sleep(0.3)
        except:
            break
            
    return pd.DataFrame(posts).drop_duplicates()

# --- ì›¹ í™”ë©´ êµ¬ì„± ---
st.set_page_config(page_title="ë„¤ì´ë²„ ë¸”ë¡œê·¸ ìˆ˜ì§‘ê¸°", layout="centered")
st.title("ðŸ“ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê¸€ ëª©ë¡ ì¶”ì¶œê¸°")
st.write("ë¸”ë¡œê·¸ ì•„ì´ë””ë¥¼ ìž…ë ¥í•˜ë©´ ê¸€ ëª©ë¡ì„ ì—‘ì…€ë¡œ ë§Œë“¤ì–´ ë“œë¦½ë‹ˆë‹¤.")

blog_url = st.text_input("ë¸”ë¡œê·¸ ì£¼ì†Œ ë˜ëŠ” ì•„ì´ë”” ìž…ë ¥", "youngwookim77")

if st.button("ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘"):
    # ì£¼ì†Œì—ì„œ ì•„ì´ë””ë§Œ ì¶”ì¶œí•˜ëŠ” ë¡œì§
    blog_id = blog_url.split('/')[-1] if '/' in blog_url else blog_url
    
    with st.spinner('ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...'):
        df = get_blog_posts(blog_id)
        
    if not df.empty:
        st.success(f"ì´ {len(df)}ê°œì˜ ê¸€ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        st.dataframe(df.head(10))  # ë¯¸ë¦¬ë³´ê¸°
        
        # ì—‘ì…€ íŒŒì¼ ë³€í™˜ (ë©”ëª¨ë¦¬ ìƒì—ì„œ ì²˜ë¦¬)
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False)
        
        st.download_button(
            label="ðŸ“Š ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=output.getvalue(),
            file_name=f"blog_{blog_id}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.error("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì•„ì´ë””ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")